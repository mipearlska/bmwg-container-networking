Refer: 
https://github.com/huyng14/bmwg-container-network/tree/main/roles/userspace-cni-install/tasks

# Prerequisites
### Install meson ninja
OS system: CentOS Linux release 7.9.2009 (Core)
Kernel: 3.10.0-1160.11.1.el7.x86_64
VPP: vpp v19.04.4-rc0~5-ge88582f~b138
DPDK: DPDK 19.02.0

`https://mesonbuild.com/SimpleStart.html`

```bash
sudo dnf install meson ninja-build

yum install epel-release
yum install gcc gcc-c++
yum install meson
```



# C1.vpp-install.yml
### install dependencies on Red Hat
- pygpgme
- yum-utils
  `sudo yum install -y pygpgme yum-utils`
# C2.setup vpp repo on Red Hat
`python -c 'import yum, json; yb = yum.YumBase(); print json.dumps(yb.conf.yumvar, indent=2)'`
```
Example output:
This system is not registered with an entitlement server. You can use subscription-manager to register.

{
  "uuid": "1cb1e6cb-2444-49f9-926f-ed46389a6a27",
  "contentdir": "centos",
  "basearch": "x86_64",
  "infra": "stock",
  "releasever": "7",
  "arch": "ia32e"
}
```
### Configure hugepages, shmmax
`sysctl -n kernel.shmmax vm.max_map_count`

### install vpp packages on Red Hat
`yum install -y vpp vpp-plugins vpp-devel vpp-api-python vpp-api-lua vpp-api-java`

`yum install -y vpp vpp-lib vpp-plugins vpp-devel vpp-api-python vpp-api-lua vpp-selinux-policy`

### write sys config with hugepages and memory settings
1. edit file `/etc/sysctl.d/80-vpp.conf`

```
Example output:
# Number of 2MB hugepages desired
vm.nr_hugepages=1024

# Must be greater than or equal to (2 * vm.nr_hugepages).
vm.max_map_count=3096

# All groups allowed to access hugepages
vm.hugetlb_shm_group=0

# Shared Memory Max must be greater or equal to the total size of hugepages.
# For 2MB pages, TotalHugepageSize = vm.nr_hugepages * 2 * 1024 * 1024
# If the existing kernel.shmmax setting  (cat /sys/proc/kernel/shmmax)
# is greater than the calculated TotalHugepageSize then set this parameter
# to current shmmax value.
kernel.shmmax=2147483648
```
2. apply sysctl config
`sysctl -p --load=/etc/sysctl.d/80-vpp.conf`

3. Restart VPP service
`systemctl restart vpp`

# C3. build Userspace CNI plugin
### create /opt/cni/bin
1.
`cd /opt/cni/bin`

2. set path to the Userspace CNI plugin sources
[userspace CNI guideline](install-userspacecni-v1.md)
`cat ~/.bash_profile`

```
export GOPATH=/usr/local/go/bin
export CNI_PATH=$GOPATH/src/github.com/containernetworking/plugins/bin

PATH=$PATH:$GOPATH
export PATH
```

3. clone Userspace CNI Plugin repository
`git clone https://github.com/intel/userspace-cni-network-plugin.git`
```
commit c2d9bb501af725ca682af32664ec9fb07f8f8c28
Merge: 807c523 62fd3ff
Author: Gary Loughnane <gary.loughnane@intel.com>
Date:   Tue Nov 24 15:28:20 2020 +0000

    Merge pull request #58 from patrickog11/useless-variables

    remove useless variables
```

4. build Userspace CNI plugin
```
cd $GOPATH/src/
go get github.com/intel/userspace-cni-network-plugin
cd github.com/intel/userspace-cni-network-plugin
make
```

5.  copy built Userspace CNI plugin binary to the CNI bin dir
`cp userspace/userspace /opt/cni/bin/`


# C4.Configure net-attach-defs
`kubectl apply -f userspace-vpp-CRD.yaml`

> [root@master userspaceCNI]# cat userspace-vpp-CRD.yaml
> apiVersion: "k8s.cni.cncf.io/v1"
> kind: NetworkAttachmentDefinition
> metadata:
>   name: **userspace-vpp-net**
> spec:
>   config: '{
>         "cniVersion": "0.3.1",
>         "type": "**userspace**",
>         "name": "userspace-vpp-net-1",
>         "kubeconfig": "/etc/cni/net.d/multus.d/multus.kubeconfig",
>         "logFile": "/var/log/userspace-vpp-net-1-cni.log",
>         "logLevel": "debug",
>         "host": {
>                 "engine": "vpp",
>                 "iftype": "memif",
>                 "netType": "bridge",
>                 "memif": {
>                         "role": "master",
>                         "mode": "ethernet"r
>                 },
>                 "bridge": {
>                         "bridgeName": "4"
>                 }
>         },
>         "container": {
>                 "engine": "vpp",
>                 "iftype": "memif",
>                 "netType": "interface",
>                 "memif": {
>                         "role": "slave",
>                         "mode": "ethernet"
>                 }
>         }
>     }'

```bash
apiVersion: "k8s.cni.cncf.io/v1"
kind: NetworkAttachmentDefinition
metadata:
  name: userspace-vpp-net
spec:
  config: '{
        "cniVersion": "0.3.1",
        "type": "userspace",
        "name": "userspace-vpp-net-1",
        "kubeconfig": "/etc/cni/net.d/multus.d/multus.kubeconfig",
        "logFile": "/var/log/userspace-vpp-net-1-cni.log",
        "logLevel": "debug",
        "host": {
                "engine": "vpp",
                "iftype": "memif",
                "netType": "bridge",
                "memif": {
                        "role": "master",
                        "mode": "ethernet"
                },
                "bridge": {
                        "bridgeName": "4"
                }
        },
        "container": {
                "engine": "vpp",
                "iftype": "memif",
                "netType": "interface",
                "memif": {
                        "role": "slave",
                        "mode": "ethernet"
                }
        }
    }'

```

`kubectl get net-attach-def`

```
Example output:
root@master ~# kubectl get net-attach-def
NAME                AGE
userspace-vpp-net   25m
```

# C5.Install & configure Multus CNI
**On master node:**

1. Download multus
    `git clone https://github.com/intel/multus-cni.git`
    
    > commit d4e86998253d2c0d44f3d8317887ff7c926e7756
    > Author: dougbtv <dosmith@redhat.com>
    > Date:   Wed Dec 16 15:12:33 2020 -0500
    >
    > The readme links need to be updated after directory change.
    >
    > This updates the links to point to "doc/" instead of "docs/"
    
2. Create Multus & CRD
    `cd multus-cni/images/`
    `kubectl apply -f multus-daemonset.yml`

3. Create CRD
[userspace-vpp-CRD.yaml](./userspaceCNI-yaml/userspace-vpp-CRD.yaml)
    `kubectl apply -f userspace-vpp-CRD.yaml`

4. Edit /etc/cni/net.d/00-multus.conf 
- on Worker node: (running default configuration) (flannel run as a primary interface)
```bash
cat << EOF > 00-multus.conf
{ "cniVersion": "0.3.1", "name": "multus-cni-network", "type": "multus", "kubeconfig": "/etc/cni/net.d/multus.d/multus.kubeconfig", "delegates": [ { "name": "cbr0", "cniVersion": "0.3.1", "plugins": [ { "type": "flannel", "delegate": { "hairpinMode": true, "isDefaultGateway": true } }, { "type": "portmap", "capabilities": { "portMappings": true } } ] } ] }
EOF
```

### Configure VPP before run next step 
[Configure VPP](2.Configure-VPP.md)
# C6.Create PoD using Flannel & userspace CNI
Note:
DPDK application for POD: `docker pull huyng14/dpdkapp-v20.05`
```
root@master ~/t/userspaceCNI# cat << EOF > vpp-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: vpp-pod
  annotations:
    k8s.v1.cni.cncf.io/networks: userspace-vpp-net, userspace-vpp-net
spec:
  containers:
  - name: multi-memif
    image: huyng14/dpdkapp-v20.05
    imagePullPolicy: IfNotPresent
    terminationMessagePath: "/tmp/vpp/"
    command: [ "/bin/bash", "-c", "--" ]
    args: [ "while true; do sleep 30; done;" ]
    securityContext:
      privileged: true
    volumeMounts:
    - mountPath: /etc/podinfo
      name: podinfo
      readOnly: false
    - mountPath: /var/run/vpp/cni/usrspcni
      name: shared-dir
    - mountPath: /dev/hugepages
      name: hugepage
    resources:
      requests:
        memory: 2Mi
        hugepages-2Mi: 512Mi
      limits:
        hugepages-2Mi: 512Mi
#  nodeSelector:
#    vswitch: vpp
  volumes:
  - name: podinfo
    downwardAPI:
      items:
        - path: "labels"
          fieldRef:
            fieldPath: metadata.labels
        - path: "annotations"
          fieldRef:
            fieldPath: metadata.annotations
  - name: shared-dir
    hostPath:
      path: /var/run/vpp/cni/usrspcni/data
  - name: hugepage
    emptyDir:
      medium: HugePages
EOF
```
`kubectl apply -f vpp-pod.yaml`

`kubectl describe pod vpp-pod.yaml`
```
> root@master ~# kubectl describe pod vpp-pod
> 
> Name:         userspace-vpp-pod-1
> Namespace:    default
> Priority:     0
> Node:         worker/192.168.26.41
> Start Time:   Sat, 06 Feb 2021 01:41:30 -0500
> Labels:       <none>
> Annotations:  k8s.v1.cni.cncf.io/network-status:
>                 [{
>                     "name": "",
>                     "interface": "eth0",
>                     "ips": [
>                         "10.244.1.240"
>                     ],
>                     "mac": "56:ce:b9:ca:8e:fa",
>                     "default": true,
>                     "dns": {}
>                 },{
>                     "name": "default/userspace-vpp-net",
>                     "interface": "net1",
>                     "dns": {}
>                 },{
>                     "name": "default/userspace-vpp-net",
>                     "interface": "net2",
>                     "dns": {}
>                 }]
>               k8s.v1.cni.cncf.io/networks: userspace-vpp-net, userspace-vpp-net
>               k8s.v1.cni.cncf.io/networks-status:
>                 [{
>                     "name": "",
>                     "interface": "**eth0**",
>                     "ips": [
>                         "10.244.1.240"
>                     ],
>                     "mac": "56:ce:b9:ca:8e:fa",
>                     "default": true,
>                     "dns": {}
>                 },{
>                     "name": "default/userspace-vpp-net",
>                     "interface": "**net1**",
>                     "dns": {}
>                 },{
>                     "name": "default/userspace-vpp-net",
>                     "interface": "**net2**",
>                     "dns": {}
>                 }]
>               userspace/configuration-data:
>                 [{
>                     "containerId": "52e05e715e978b17224d3f2a045e9b52acde01d263078e1bed1c084bb28ded55",
>                     "ifName": "net1",
>                     "name": "userspace-vpp-net-1",
>                     "config": {
>                         "engine": "vpp",
>                         "iftype": "memif",
>                         "netType": "interface",
>                         "memif": {
>                             "role": "slave",
>                             "mode": "ethernet",
>                             "socketfile": "memif-52e05e715e97-net1.sock"
>                         },
>                         "vhost": {},
>                         "bridge": {}
>                     },
>                     "ipResult": {
>                         "interfaces": [
>                             {
>                                 "name": "net1",
>                                 "sandbox": "/proc/217159/ns/net"
>                             }
>                         ],
>                         "dns": {}
>                     }
>                 },{
>                     "containerId": "52e05e715e978b17224d3f2a045e9b52acde01d263078e1bed1c084bb28ded55",
>                     "ifName": "net2",
>                     "name": "userspace-vpp-net-1",
>                     "config": {
>                         "engine": "vpp",
>                         "iftype": "memif",
>                         "netType": "interface",
>                         "memif": {
>                             "role": "slave",
>                             "mode": "ethernet",
>                             "socketfile": "memif-52e05e715e97-net2.sock"
>                         },
>                         "vhost": {},
>                         "bridge": {}
>                     },
>                     "ipResult": {
>                         "interfaces": [
>                             {
>                                 "name": "net2",
>                                 "sandbox": "/proc/217159/ns/net"
>                             }
>                         ],
>                         "dns": {}
>                     }
>                 }]
>               userspace/mapped-dir: /var/lib/cni/usrspcni/
> Status:       Running
> IP:           10.244.1.240
> IPs:
>   IP:  10.244.1.240
> Containers:
>   multi-memif-example:
>     Container ID:   docker://9b97646a89651063da8a8f5263354e5f20389def92fc2fb194467a5d19123ff5
>     Image:          bmcfall/dpdk-app-centos:latest
>     Image ID:       docker-pullable://docker.io/bmcfall/dpdk-app-centos@sha256:fca82359b69a580a8744c4ea4cc9f460ebe58334b772c92ac26efdba8ac513f5
>     Port:           <none>
>     Host Port:      <none>
>     State:          Running
>       Started:      Sat, 06 Feb 2021 01:41:32 -0500
>     Ready:          True
>     Restart Count:  0
>     Limits:
>       hugepages-2Mi:  512Mi
>     Requests:
>       hugepages-2Mi:  512Mi
>       memory:         2Mi
>     Environment:      <none>
>     Mounts:
>       /dev/hugepages from hugepage (rw)
>       /etc/podinfo from podinfo (rw)
>       /var/lib/cni/usrspcni/ from shared-dir (rw)
>       /var/run/secrets/kubernetes.io/serviceaccount from default-token-7rkfp (ro)
> Conditions:
>   Type              Status
>   Initialized       True
>   Ready             True
>   ContainersReady   True
>   PodScheduled      True
> Volumes:
>   podinfo:
>     Type:  DownwardAPI (a volume populated by information about the pod)
>     Items:
>       metadata.labels -> labels
>       metadata.annotations -> annotations
>   shared-dir:
>     Type:          HostPath (bare host directory volume)
>     Path:          /var/run/vpp/023bcd123/
>     HostPathType:
>   hugepage:
>     Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
>     Medium:     HugePages
>     SizeLimit:  <unset>
>   default-token-7rkfp:
>     Type:        Secret (a volume populated by a Secret)
>     SecretName:  default-token-7rkfp
>     Optional:    false
> QoS Class:       Burstable
> Node-Selectors:  <none>
> Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
>                  node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
> Events:
>   Type    Reason     Age   From               Message
>
> ----    ------     ----  ----               -------
>   Normal  Scheduled  26m   default-scheduler  Successfully assigned default/userspace-vpp-pod-1 to worker
>   Normal  Pulled     26m   kubelet            Container image "bmcfall/dpdk-app-centos:latest" already present on machine
>   Normal  Created    26m   kubelet            Created container multi-memif-example
>   Normal  Started    26m   kubelet            Started container multi-memif-example
```
- Check memif on vpp
```
  > [root@**worker** ~]# sudo vppctl show interface
  >
  >               Name               Idx    State  MTU (L3/IP4/IP6/MPLS)     Counter          Count
  > FortyGigabitEthernetaf/0/0        1     down         9000/0/0/0
  > FortyGigabitEthernetaf/0/1        2     down         9000/0/0/0
  > local0                            0     down          0/0/0/0
  > memif1/0                          3      up          9000/0/0/0
  > memif2/0                          4      up          9000/0/0/0
```
# C7.Run L2fwd, L3fwd, testpmd on POD

- On master node:

`kubectl exec -it vpp-pod -- /bin/bash`

Each application runs on a different socket. Show socket file: `ls -la /run/vpp/cni/usrspcni`

```
l2fwd -n 4 -l 7-10 --master-lcore 7 --vdev=net_memif1,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net1.sock,role=slave --vdev=net_memif2,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net2.sock,role=slave --no-pci -- -p 0x3 -T 10 --no-mac-updating

testpmd --huge-dir=/dev/hugepages --file-prefix=huge -l 1,2 --vdev=net_memif1,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net1.sock --vdev=net_memif2,socket=/run/vpp/cni/usrspcni/memif-6afac1a69b32-net2.sock -n 2 -- -i --txd=1024 --rxd=1024
```

